sc <- lapply(len, function(x){wbpg_items[[x]][["score"]]})
df <- data.frame(PostID=unlist(pId), CommentID=unlist(cmtId), CreationDate=as_datetime(unlist(creaDate)),
Score=unlist(sc))
cmt_df <- rbind(cmt_df, df)
i <- i+1
}
cmt_df
}
Comnt_query <- function(quesId){
cmt_df <- data.frame(PostID=integer(), CommentID=integer(),
CreationDate=POSIXct(), Score=integer())
i <- 1
repeat{
if(i>length(quesId)){
break
}
wbpg <- paste0("https://api.stackexchange.com/2.2/questions/", quesId[i], "/comments?key=", key, "&pagesize=100&order=desc&sort=votes&access_token=", token, "&tagged=r&site=stackoverflow")
wbpg <- GET(wbpg)
wbpg_jsonParsed <- content(wbpg, as="parsed")
wbpg_items <- wbpg_jsonParsed$items
len <- as.vector(1:length(wbpg_items))
if(length(wbpg_items)==0){
i <- i+1
next
}
pId <- lapply(len, function(x){wbpg_items[[x]][["post_id"]]})
cmtId <- lapply(len, function(x){wbpg_items[[x]][["comment_id"]]})
creaDate <- lapply(len, function(x){wbpg_items[[x]][["creation_date"]]})
sc <- lapply(len, function(x){wbpg_items[[x]][["score"]]})
df <- data.frame(PostID=unlist(pId), CommentID=unlist(cmtId), CreationDate=as_datetime(unlist(creaDate)),
Score=unlist(sc))
cmt_df <- rbind(cmt_df, df)
i <- i+1
}
cmt_df
}
asdfff <- Comnt_query(questionId)
rm(list = ls())
key <- "SX945TWflISfN*DzZ*G53w(("
token <- "ixiOsNGGzzlmAyggyT1rRA))"
library(httr)
library(rlist)
library(jsonlite)
library(dplyr)
library(lubridate)
Ques_query <- function(fromDate, toDate, pg=1){
fromDate <- as.numeric(as.POSIXct(fromDate, tz="UTC"))
toDate <- as.numeric(as.POSIXct(toDate, tz="UTC"))
ques_df <- data.frame(ID=integer(), Title=character(), View_Count=integer(),
Answer=logical(), Link=character())
repeat{
wbpg <- paste0("https://api.stackexchange.com/2.2/questions?key=", key, "&page=", pg, "&pagesize=100&fromdate=", fromDate, "&todate=", toDate, "&order=desc&sort=activity&access_token=", token, "&tagged=r&site=stackoverflow")
wbpg <- GET(wbpg)
wbpg_jsonParsed <- content(wbpg, as="parsed")
wbpg_items <- wbpg_jsonParsed$items
if(length(wbpg_items)==0){
break
}
len <- as.vector(1:length(wbpg_items))
quesId <- lapply(len, function(x){wbpg_items[[x]][["question_id"]]})
quesTitle <- lapply(len, function(x){wbpg_items[[x]][["title"]]})
quesViewCount <- lapply(len, function(x){wbpg_items[[x]][["view_count"]]})
quesAnswered <- lapply(len, function(x){wbpg_items[[x]][["is_answered"]]})
quesLink <- lapply(len, function(x){wbpg_items[[x]][["link"]]})
df <- data.frame(ID=unlist(quesId), Title=unlist(quesTitle), View_Count=unlist(quesViewCount),
Answer=unlist(quesAnswered), Link=unlist(quesLink))
ques_df <- rbind(ques_df, df)
pg <- pg + 1
}
ques_df
}
# Obtaining list of Question IDs whose Answer is PRESENT on Stack Overflow
Ques_df <- Ques_query("2021-01-01", "2021-01-02")
temp_ques_df <- filter(Ques_df, Answer==TRUE)
questionId <- temp_ques_df$ID
Ans_query <- function(quesId){
ans_df <- data.frame(QuestionID=integer(), AnswerID=integer(),
CreationDate=POSIXct(), Score=integer(), Accepted=logical())
i <- 1
repeat{
if(i>length(quesId)){
break
}
wbpg <- paste0("https://api.stackexchange.com/2.2/questions/", quesId[i], "/answers?key=", key, "&pagesize=100&order=desc&sort=activity&access_token=", token, "&tagged=r&site=stackoverflow")
wbpg <- GET(wbpg)
wbpg_jsonParsed <- content(wbpg, as="parsed")
wbpg_items <- wbpg_jsonParsed$items
len <- as.vector(1:length(wbpg_items))
qId <- lapply(len, function(x){wbpg_items[[x]][["question_id"]]})
aId <- lapply(len, function(x){wbpg_items[[x]][["answer_id"]]})
creaDate <- lapply(len, function(x){wbpg_items[[x]][["creation_date"]]})
sc <- lapply(len, function(x){wbpg_items[[x]][["score"]]})
isAcc <- lapply(len, function(x){wbpg_items[[x]][["is_accepted"]]})
df <- data.frame(QuestionID=unlist(qId), AnswerID=unlist(aId), CreationDate=as_datetime(unlist(creaDate)),
Score=unlist(sc), Accepted=unlist(isAcc))
ans_df <- rbind(ans_df, df)
i <- i+1
}
ans_df
}
asdm <- Ans_query(questionId)
# Obtaining Question IDs from `Query_df` function
questionId <- Ques_df$ID
Comnt_query <- function(quesId){
cmt_df <- data.frame(PostID=integer(), CommentID=integer(),
CreationDate=POSIXct(), Score=integer())
i <- 1
repeat{
if(i>length(quesId)){
break
}
wbpg <- paste0("https://api.stackexchange.com/2.2/questions/", quesId[i], "/comments?key=", key, "&pagesize=100&order=desc&sort=votes&access_token=", token, "&tagged=r&site=stackoverflow")
wbpg <- GET(wbpg)
wbpg_jsonParsed <- content(wbpg, as="parsed")
wbpg_items <- wbpg_jsonParsed$items
len <- as.vector(1:length(wbpg_items))
if(length(wbpg_items)==0){
i <- i+1
next
}
pId <- lapply(len, function(x){wbpg_items[[x]][["post_id"]]})
cmtId <- lapply(len, function(x){wbpg_items[[x]][["comment_id"]]})
creaDate <- lapply(len, function(x){wbpg_items[[x]][["creation_date"]]})
sc <- lapply(len, function(x){wbpg_items[[x]][["score"]]})
df <- data.frame(PostID=unlist(pId), CommentID=unlist(cmtId), CreationDate=as_datetime(unlist(creaDate)),
Score=unlist(sc))
cmt_df <- rbind(cmt_df, df)
i <- i+1
}
cmt_df
}
meet <- Comnt_query(questionId)
View(meet)
rm(list = ls())
install.packages(c("backports", "broom", "cli", "cpp11", "crayon", "data.table", "dbplyr", "desc", "dplyr", "farver", "fastmap", "forcats", "gert", "ggforce", "ggraph", "htmltools", "isoband", "ISOcodes", "knitr", "lifecycle", "lubridate", "MatrixModels", "matrixStats", "memoise", "mime", "packageRank", "pillar", "pkgload", "promises", "ps", "quantreg", "rappdirs", "RcppArmadillo", "RCurl", "reprex", "rgl", "rmarkdown", "rvest", "shiny", "shinythemes", "SparseM", "stopwords", "systemfonts", "testthat", "tibble", "tidyr", "tinytex", "usethis", "utf8", "waldo", "withr", "xfun"))
# storing API keys
api_key <- "Vasln0HaAY8pkXu7J2xQkBX8c"
api_secret_key <- "h5ra23jvrY8nq7vkUBld1mXXYwjsKR5iyNoH2CATUNKO1rdzq3"
acc_token <- "1013338789580713984-2oRZj3Btzvgl0yZqJ8Wfr0GEmTzW34"
acc_secret <- "92oQXpMxvdNI7gwIAji2ZfEdN905eGudFoeNWd4sb6Wnn"
library(rtweet)
token <- create_token(
app = "RtweetsExploration",
consumer_key = api_key,
consumer_secret = api_secret_key,
access_token = acc_token,
access_secret = acc_secret
)
get_followers(user = "@sachin_rt")
get_followers(user = "sachin_rt")
get_followers(user = "@sachin_rt", n=100)
df <- get_followers(user = "@sachin_rt", n=100)
View(df)
usrs <- lookup_users(df$user_id)
View(usrs)
user_names <- usrs$screen_name
user_names
library(rtweet)
# searching for required #rstats tweets
rtweet_data <- search_tweets(q="#rstats", since = Sys.Date()-1,
until = Sys.Date(),
retryonratelimit = TRUE, include_rts = FALSE)
View(rtweet_data)
install.packages(c("bioC.logs", "BiocManager", "bitops", "brglm", "brio", "broom", "bslib", "cachem", "callr", "cli", "colorspace", "cpp11", "curl", "dbplyr", "devtools", "diffobj", "dplyr", "DT", "ellipsis", "entropy", "gert", "gh", "haven", "highr", "httpuv", "installr", "jquerylib", "knitr", "later", "lme4", "openintro", "openssl", "packageRank", "parsedate", "pdftools", "pillar", "pkgload", "processx", "raster", "rco", "RcppArmadillo", "RCurl", "remotes", "renv", "reprex", "rgl", "rlang", "rmarkdown", "sass", "statmod", "stringi", "systemfonts", "taskscheduleR", "tibble", "tidyselect", "tidytext", "tidyverse", "tinytex", "tweenr", "vctrs", "viridis", "viridisLite", "withr", "xfun"))
library(rvest)
wbpg <- read_html("https://www.r-bloggers.com/blogs-list/")
blog_typename <- wbpg %>%
html_nodes("#content a") %>%
html_text()
blog_typecount <- length(blog_typename)
blog_typename <- wbpg %>%
html_nodes(".entry a") %>%
html_text()
blog_typecount <- length(blog_typename)
library(rvest)
wbpg <- read_html("https://www.r-bloggers.com/blogs-list/")
blog_typename <- wbpg %>%
html_nodes(".entry a") %>%
html_text()
blog_typecount <- length(blog_typename)
blog_typecount <- length(blog_typename)
library(purrr)
main_wbpg <- read_html("https://www.r-bloggers.com/")
pg_max <- main_wbpg %>%
html_nodes(".dots+ .page-numbers") %>%
html_text()
pg_max <- 1:as.numeric(gsub(",", "", pg_max))
# Important points to note down here are as follows:
# 'pg_max' variable gives the number of blog pages available on R-bloggers
# BUT!!!! the max number I can access on the website is till page number 45.
# So, in my mapping function which created the data-frame named 'Blog_Information'
# I have taken input from page 1 till page 45.
# As soon as the website allows till 'pg_max' just put "pg_max" instead of "1:45" as input
surf_wbpg <- "https://www.r-bloggers.com/page/%d/"
map_df(1:45, function(i){
page <- read_html(sprintf(surf_wbpg, i))
blog_title <- page %>%
html_nodes(".loop-title a") %>%
html_text()
blog_author <- page %>%
html_nodes(".fn") %>%
html_text()
blog_date <- page %>%
html_nodes(".meta") %>%
html_text()
blog_date <- gsub(" \\|.*","",blog_date)
data.frame(Title = blog_title,
Date = blog_date,
Author = blog_author)
}) -> Blog_Information
View(Blog_Information)
# month wise function - combines full data into data-frame for that particular month and year as input
month_blogs <- function(year, month){
ym_wbpg <- "https://www.r-bloggers.com/%d/%d/"
ym_wbpg <- sprintf(ym_wbpg, year, month)
temp_wbpg <- paste0(ym_wbpg, "page/2/")
xpage <- read_html(temp_wbpg)
pg_ym_max <- xpage %>%
html_nodes(".dots+ .page-numbers") %>%
html_text()
pg_ym_max <- 1:as.numeric(gsub(",", "", pg_ym_max))
remove(temp_wbpg)
surf_wbpg <- paste0(ym_wbpg, "page/%d/")
map_df(pg_ym_max, function(i){
page <- read_html(sprintf(surf_wbpg, i))
blog_title <- page %>%
html_nodes(".loop-title a") %>%
html_text()
blog_author <- page %>%
html_nodes(".fn") %>%
html_text()
blog_date <- page %>%
html_nodes(".meta") %>%
html_text()
blog_date <- gsub(" \\|.*","",blog_date)
author_blogs_hyperlink <- page %>%
html_nodes("[class='fn']") %>%
html_attr("href")
data.frame(Title = blog_title,
Date = blog_date,
Author = blog_author,
Author_Hyperlink = author_blogs_hyperlink)
}) -> Month_Blog_Information
Month_Blog_Information
}
df <- month_blogs(2021, 1)
View(df)
# year wise function - combines full data into data-frame for that particular year as input
year_blogs <- function(year_date){
map_df(1:12, function(i){
month_blogs(year = year_date, month = i)
}) -> Year_Blog_Information
Year_Blog_Information
}
temp_df <- year_blogs(2020)
View(temp_df)
library(dplyr)
df <- temp_df[!duplicated(temp_df$Title),]
View(df)
data <- toString(df$Title)
data
data <- gsub('[[:punct:] ]+',' ',data)
data
docs <- VCorpus(VectorSource(data))
library(NLP)
library(tm)
library(wordcloud)
library(RColorBrewer)
library(SnowballC)
docs <- VCorpus(VectorSource(data))
docs <- tm_map(docs, content_transformer(tolower))
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, removeWords, stopwords("english"))
docs <- tm_map(docs, removePunctuation)
docs <- tm_map(docs, stripWhitespace)
docs <- tm_map(docs, stemDocument)
docs <- tm_map(docs, PlainTextDocument)
dtm <- TermDocumentMatrix(docs)
View(docs)
docs <- VCorpus(VectorSource(data))
View(docs)
docs <- tm_map(docs, content_transformer(tolower))
View(docs)
docs <- VCorpus(VectorSource(data))
docs[["1"]][["content"]]
filePath <- "http://www.sthda.com/sthda/RDoc/example-files/martin-luther-king-i-have-a-dream-speech.txt"
text <- readLines(filePath)
docs <- Corpus(VectorSource(text))
View(docs)
View(docs)
inspect(docs)
docs <- Corpus(VectorSource(data))
View(docs)
docs <- tm_map(docs, content_transformer(tolower))
View(docs)
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, removeWords, stopwords("english"))
docs <- tm_map(docs, removePunctuation)
docs <- tm_map(docs, stripWhitespace)
docs <- tm_map(docs, stemDocument)
docs <- tm_map(docs, PlainTextDocument)
dtm <- TermDocumentMatrix(docs)
m <- as.matrix(dtm)
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
head(d, 10)
View(docs)
View(d)
class(data)
data <- df$Title
data
docs <- Corpus(VectorSource(data))
docs <- tm_map(docs, content_transformer(tolower))
View(docs)
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, removeWords, stopwords("english"))
docs <- tm_map(docs, removePunctuation)
docs <- tm_map(docs, stripWhitespace)
docs <- tm_map(docs, stemDocument)
docs <- tm_map(docs, PlainTextDocument)
dtm <- TermDocumentMatrix(docs)
data <- toString(df$Title)
data
data <- gsub('[[:punct:] ]+',' ',data)
data
data <- gsub('[[:punct:] ]+',' ',data)
data
data <- toString(df$Title)
qq <- str_replace_all(data, "[[:punct:]]", " ")
library(stringr)
qq <- str_replace_all(data, "[[:punct:]]", " ")
qq
data <- str_replace_all(data, "[[:punct:]]", " ")
library(NLP)
library(tm)
library(wordcloud)
library(RColorBrewer)
library(SnowballC)
docs <- Corpus(VectorSource(data))
docs <- tm_map(docs, content_transformer(tolower))
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, removeWords, stopwords("english"))
docs <- tm_map(docs, removePunctuation)
docs <- tm_map(docs, stripWhitespace)
docs <- tm_map(docs, stemDocument)
docs <- tm_map(docs, PlainTextDocument)
dtm <- TermDocumentMatrix(docs)
m <- as.matrix(dtm)
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
View(d)
docs <- Corpus(VectorSource(data), readerControl = list(reader=readPlain, language="en"))
docs <- tm_map(docs, content_transformer(tolower))
View(docs)
docs[["1"]][["content"]]
docs <- tm_map(docs, removeNumbers)
docs[["1"]][["content"]]
docs <- tm_map(docs, removeWords, stopwords("english"))
docs[["1"]][["content"]]
docs <- tm_map(docs, stripWhitespace)
docs[["1"]][["content"]]
dtm <- TermDocumentMatrix(docs)
m <- as.matrix(dtm)
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
View(d)
head(d, 10)
head(d, 20)
set.seed(1234)
View(d)
wordcloud(words = d$word, freq = d$freq, min.freq = 10,
max.words=550, random.order=FALSE, rot.per=0.35,
colors=rev(colorRampPalette(brewer.pal(9,"Blues"))(32)[seq(8,32,6)]))
blog_wordcloud <- function(year){
temp_df <- year_blogs(year)
df <- temp_df[!duplicated(temp_df$Title),]
data <- toString(df$Title)
data <- str_replace_all(data, "[[:punct:]]", " ")
docs <- Corpus(VectorSource(data), readerControl = list(reader=readPlain, language="en"))
docs <- tm_map(docs, content_transformer(tolower))
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, removeWords, stopwords("english"))
docs <- tm_map(docs, stripWhitespace)
dtm <- TermDocumentMatrix(docs)
m <- as.matrix(dtm)
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
head(d, 20)
set.seed(1234)
wordcloud(words = d$word, freq = d$freq, min.freq = 10,
max.words=550, random.order=FALSE, rot.per=0.35,
colors=rev(colorRampPalette(brewer.pal(9,"Blues"))(32)[seq(8,32,6)]))
}
blog_wordcloud(2019)
wordcloud(words = d$word, freq = d$freq, min.freq = 1,
max.words=500, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
View(d)
wordcloud(words = d$word, freq = d$freq, min.freq = 40,
max.words=550, random.order=FALSE, rot.per=0.35,
colors=rev(colorRampPalette(brewer.pal(9,"Blues"))(32)[seq(8,32,6)]))
wordcloud(words = d$word, freq = d$freq, min.freq = 20,
max.words=550, random.order=FALSE, rot.per=0.35,
colors=rev(colorRampPalette(brewer.pal(9,"Blues"))(32)[seq(8,32,6)]))
wordcloud(words = d$word, freq = d$freq, min.freq = 10,
max.words=550, random.order=FALSE, rot.per=0.35,
colors=rev(colorRampPalette(brewer.pal(9,"Blues"))(32)[seq(8,32,6)]))
wordcloud(words = d$word, freq = d$freq, min.freq = 1,
max.words=550, random.order=FALSE, rot.per=0.35,
colors=rev(colorRampPalette(brewer.pal(9,"Blues"))(32)[seq(8,32,6)]))
wordcloud(words = d$word, freq = d$freq, min.freq = 10,
max.words=550, random.order=FALSE, rot.per=0.35,
colors=rev(colorRampPalette(brewer.pal(9,"Blues"))(32)[seq(8,32,6)]))
wordcloud(words = d$word, freq = d$freq, min.freq = 41,
max.words=550, random.order=FALSE, rot.per=0.35,
colors=rev(colorRampPalette(brewer.pal(9,"Blues"))(32)[seq(8,32,6)]))
wordcloud(words = d$word, freq = d$freq, min.freq = 31,
max.words=550, random.order=FALSE, rot.per=0.35,
colors=rev(colorRampPalette(brewer.pal(9,"Blues"))(32)[seq(8,32,6)]))
wordcloud(words = d$word, freq = d$freq, min.freq = 20,
max.words=550, random.order=FALSE, rot.per=0.35,
colors=rev(colorRampPalette(brewer.pal(9,"Blues"))(32)[seq(8,32,6)]))
wordcloud(words = d$word, freq = d$freq, min.freq = 15,
max.words=550, random.order=FALSE, rot.per=0.35,
colors=rev(colorRampPalette(brewer.pal(9,"Blues"))(32)[seq(8,32,6)]))
"hello"
ques_barplot_wordcloud <- function(start_year, end_year){
year <- start_year:end_year
str <- ""
i <- 1
repeat{
path <- paste0("StackExch_data/Questions/",year[i],"/",year[i],"_Combined.rds")
temp_df <- readRDS(file = path)
data <- toString(temp_df$Title)
str <- paste(str, data)
i <- i+1
if(i>length(year)){
break
}
}
str <- tolower(str)
str  <- gsub("[^0-9A-Za-z///' ]", " ", str, ignore.case = TRUE)
docs <- Corpus(VectorSource(str), readerControl = list(reader=readPlain, language="en"))
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, removeWords, stopwords("english"))
docs <- tm_map(docs, stripWhitespace)
dtm <- TermDocumentMatrix(docs)
m <- as.matrix(dtm)
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
top_words <- head(d, 20)
plot1 <- ggplot(data=top_words, aes(x=reorder(word, -freq), y=freq)) +
geom_bar(stat="identity", fill="steelblue")+
geom_text(aes(label=freq), vjust=-0.3, size=2.5)+
theme_minimal()+
theme(axis.text.x=element_text(angle=90, hjust=1))+
labs(title = "Top title words for Questions posted on StackOverflow",
x = "Words", y = "Frequency of Words")
set.seed(1234)
list(plot1,
wordcloud(words = d$word, freq = d$freq, min.freq = 1000,
max.words=1000000, random.order=FALSE, rot.per=0.35,
colors=rev(colorRampPalette(brewer.pal(9,"Blues"))(32)[seq(8,32,6)])))
}
setwd("~/GitHub/R-Community-Analysis")
ques_barplot_wordcloud <- function(start_year, end_year){
year <- start_year:end_year
str <- ""
i <- 1
repeat{
path <- paste0("StackExch_data/Questions/",year[i],"/",year[i],"_Combined.rds")
temp_df <- readRDS(file = path)
data <- toString(temp_df$Title)
str <- paste(str, data)
i <- i+1
if(i>length(year)){
break
}
}
str <- tolower(str)
str  <- gsub("[^0-9A-Za-z///' ]", " ", str, ignore.case = TRUE)
docs <- Corpus(VectorSource(str), readerControl = list(reader=readPlain, language="en"))
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, removeWords, stopwords("english"))
docs <- tm_map(docs, stripWhitespace)
dtm <- TermDocumentMatrix(docs)
m <- as.matrix(dtm)
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
top_words <- head(d, 20)
plot1 <- ggplot(data=top_words, aes(x=reorder(word, -freq), y=freq)) +
geom_bar(stat="identity", fill="steelblue")+
geom_text(aes(label=freq), vjust=-0.3, size=2.5)+
theme_minimal()+
theme(axis.text.x=element_text(angle=90, hjust=1))+
labs(title = "Top title words for Questions posted on StackOverflow",
x = "Words", y = "Frequency of Words")
set.seed(1234)
list(plot1,
wordcloud(words = d$word, freq = d$freq, min.freq = 1000,
max.words=1000000, random.order=FALSE, rot.per=0.35,
colors=rev(colorRampPalette(brewer.pal(9,"Blues"))(32)[seq(8,32,6)])))
}
ques_barplot_wordcloud(2008, 2020)
library(stringr)
library(NLP)
library(tm)
library(wordcloud)
library(RColorBrewer)
library(SnowballC)
library(ggplot2)
ques_barplot_wordcloud(2008, 2020)
